use std::fs::File;
use std::io::{BufRead, BufReader, Error, ErrorKind};
use std::io;

fn parse_float_error_to_io_error(err: std::num::ParseFloatError) -> io::Error {
    io::Error::new(io::ErrorKind::InvalidData, err)
}

fn find_mean(vec: &[f32]) -> f32 {
    let sum: f32 = vec.iter().sum();
    sum / vec.len() as f32
}

fn find_std(vec: &[f32]) -> f32 {
    let mean = find_mean(vec);
    let variance: f32 = vec.iter().map(|x| (x - mean).powi(2)).sum::<f32>() / vec.len() as f32;
    variance.sqrt()
}


fn invert_matrix(matrix: &[Vec<f32>]) -> Vec<Vec<f32>> {
    // Implementation of matrix inversion (e.g., using Gauss-Jordan elimination)
    // This implementation is omitted for brevity. You can use existing crate or library for matrix inversion if needed.
    // Make sure to handle cases such as singular or non-invertible matrices.

    // Placeholder code
    matrix.to_vec()
}
fn train_linear_regression(x_vector: &[Vec<f32>], y_vector: &[f32]) -> f32 {
    let num_samples = x_vector.len();
    let num_features = x_vector[0].len();

    let mut augmented_x = vec![vec![1.0; num_features + 1]; num_samples];
    for i in 0..num_samples {
        augmented_x[i][1..].clone_from_slice(&x_vector[i]);
    }

    let mut x_transpose_x = vec![vec![0.0; num_features + 1]; num_features + 1];
    let mut x_transpose_y = vec![0.0; num_features + 1];

    for i in 0..num_samples {
        for j in 0..=num_features {
            for k in 0..=num_features {
                x_transpose_x[j][k] += augmented_x[i][j] * augmented_x[i][k];
            }
            x_transpose_y[j] += augmented_x[i][j] * y_vector[i];
        }
    }

    let x_transpose_x_inv = invert_matrix(&x_transpose_x);
    let weights = matrix_vector_mul(&x_transpose_x_inv, &x_transpose_y);

    let weight:f32=weights[1]/300.00;  // Return the weight for the first feature (x)
    weight
}


fn matrix_vector_mul(matrix: &[Vec<f32>], vector: &[f32]) -> Vec<f32> {
    let num_rows = matrix.len();
    let num_cols = matrix[0].len();

    let mut result = vec![0.0; num_rows];

    for i in 0..num_rows {
        for j in 0..num_cols {
            result[i] += matrix[i][j] * vector[j];
        }
    }

    result
}

fn predict_linear_regression(weight: &f32, x: &f32) -> f32 {
    let bias: &f32 = weight;
    let prediction: f32 = bias + x * weight;
    println!("{:?}:bias   {:?}:x   {:?}:weight",bias,x,weight);
    prediction
}



fn main() -> Result<(), Box<dyn std::error::Error>> {
    let file: File = File::open("test.txt")?;
    let reader: BufReader<File> = BufReader::new(file);

    let mut x_values: Vec<f32> = Vec::new();
    let mut y_values: Vec<f32> = Vec::new();

    for line in reader.lines() {
        let line: Result<String, Error> = line.map_err(|e| e.into());
        if let Ok(line) = line {
            let values: Vec<f32> = line
                .split(',')
                .map(|s| s.trim().parse::<f32>().map_err(parse_float_error_to_io_error))
                .collect::<Result<Vec<f32>, io::Error>>()?;

            if values.len() >= 2 {
                let x: f32 = values[0];
                let y: f32 = values[1];
                x_values.push(x);
                y_values.push(y);
            }
        }
    }

    let x_mean: f32 = find_mean(&x_values);
    let y_mean: f32 = find_mean(&y_values);

    let x_std: f32 = find_std(&x_values);
    let y_std: f32 = find_std(&y_values);

    let standardized_x_values: Vec<f32> = x_values
        .iter()
        .map(|x: &f32| (x - x_mean) / x_std)
        .collect();

    let standardized_y_values: Vec<f32> = y_values
        .iter()
        .map(|y: &f32| (y - y_mean) / y_std)
        .collect();

    let weight: f32 = train_linear_regression(&[standardized_x_values], &standardized_y_values);

    println!("Learned weights: {:?}", weight);

    let new_x: f32 = 22.7; 

    // Make the prediction
    let prediction: f32 = predict_linear_regression(&weight, &new_x);

    println!("Predicted y for given x: {:?}   {:?}", prediction, new_x);


    Ok(())
}
